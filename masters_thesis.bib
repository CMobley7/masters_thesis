Automatically generated by Mendeley Desktop 1.17
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{ZBar,
title = {{ZBar - ROS Wiki}},
url = {http://wiki.ros.org/zbar{\_}ros},
urldate = {2016-11-07}
}
@book{Hartley2004,
author = {Hartley, Richard and Zisserman, Andrew},
edition = {Second},
isbn = {0521540518},
publisher = {Cambridge University Press},
title = {{Multiple View Geometry in Computer Vision}},
year = {2004}
}
@misc{MoveIt,
title = {{Moveit Home}},
url = {http://moveit.ros.org/},
urldate = {2016-10-30}
}
@misc{ROSConcepts,
title = {{ROS Concepts - ROS Wiki}},
url = {http://wiki.ros.org/ROS/Concepts},
urldate = {2016-10-18}
}
@book{Jacobs2012,
author = {Jacobs, Corinna and Parrish, I},
isbn = {9783642186653},
publisher = {Springer Science {\&} Business Media},
title = {{Interactive Panoramas: Techniques for Digital Panoramic Photography}},
year = {2012}
}
@misc{CoreSLAM,
title = {{CoreSLAM - ROS Wiki}},
url = {http://wiki.ros.org/coreslam},
urldate = {2016-10-28}
}
@misc{HSVColorSpace,
title = {{HSL and HSV - Wikipedia}},
url = {https://en.wikipedia.org/wiki/HSL{\_}and{\_}HSV},
urldate = {2016-10-30}
}
@inproceedings{Moore2014,
abstract = {Accurate state estimation for a mobile robot often requires the fusion of data from multiple sensors. Software that performs sensor fusion should therefore support the inclusion of a wide array of heterogeneous sensors. This paper presents a software package, robot{\_}localization, for the robot operating system (ROS). The package currently contains an implementation of an extended Kalman filter (EKF). It can support an unlimited number of inputs frommultiple sensor types, and allows users to customize which sensor data fields are fused with the current state estimate. In this work, we motivate our design decisions, discuss implementation details, and provide results from real-world tests.},
author = {Moore, Thomas and Stouch, Daniel},
booktitle = {Proceedings of the 13th International Conference on Intelligent Autonomous Systems (IAS-13)},
file = {:C$\backslash$:/Users/CMobley7/Downloads/chp{\%}3A10.1007{\%}2F978-3-319-08338-4{\_}25.pdf:pdf},
publisher = {Springer},
title = {{A Generalized Extended Kalman Filter Implementation for the Robot Operating System}},
year = {2014}
}
@book{Kelly2013,
address = {New York, NY, USA},
author = {Kelly, Alonzo},
publisher = {Cambridge University Press},
title = {{Mobile Robotics: Mathematics, Models, and Methods}},
year = {2013}
}
@inproceedings{Carlone2011,
abstract = {This article investigates the problem of Simultaneous Localization and Mapping (SLAM) from the perspective of linear estimation theory. The problem is ﬁrst formulated in terms of graph embedding: a graph describing robot poses at subsequent instants of time needs be embedded in a three-dimensional space, assuring that the estimated conﬁguration maximizes measurement likelihood. Combining tools belonging to linear estimation and graph theory, a closed-form approximation to the full SLAM problem is proposed, under the assumption that the relative position and the relative orientation measurements are independent. The approach needs no initial guess for optimization and is formally proven to admit solution under the SLAM setup. The resulting estimate can be used as an approximation of the actual nonlinear solution or can be further reﬁned by using it as an initial guess for nonlinear optimization techniques. Finally, the experimental analysis demonstrates that such reﬁnement is often unnecessary, since the linear estimate is already accurate.},
author = {Carlone, Luca and Aragues, Rosario},
booktitle = {Int. Conf. Robotics: Science and Systems},
file = {:C$\backslash$:/Users/CMobley7/Downloads/p06.pdf:pdf},
pages = {8},
title = {{A linear approximation for graph-based simultaneous localization and mapping}},
year = {2011}
}
@book{Gomaa2016,
author = {Gomaa, Hassan},
isbn = {9781107041097},
publisher = {Cambridge University Press},
title = {{Real-Time Software Design for Embedded Systems}},
year = {2016}
}
@inproceedings{Gerkey2008,
abstract = {— We consider the problem of autonomous naviga-tion in an unstructured outdoor environment. We describe the planning and control aspects of an implemented system that drives a robot at modest speeds (∼1 m/s) over a variety of outdoor terrain. In real time, we use a gradient technique to plan globally optimal paths on a cost map, then employ a predictive dynamic controller to compute local velocity commands. Our planner and controller are considered the " best in class " among 10 teams competing in the DARPA Learning Applied to Ground Robotics (LAGR) program.},
author = {Gerkey, Brian P and Konolige, Kurt},
booktitle = {ICRA Workshop on Path Planning on Costmaps},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gerkey, Konolige - Unknown - Planning and Control in Unstructured Terrain.pdf:pdf},
title = {{Planning and Control in Unstructured Terrain}},
year = {2008}
}
@misc{Navigation,
title = {{Navigation - ROS Wiki}},
url = {http://wiki.ros.org/navigation},
urldate = {2016-10-18}
}
@misc{RSGSDiff,
title = {{Key Differences Between Rolling Shutter and Frame (Global) Shutter - Point Grey Knowledge Base}},
url = {https://www.ptgrey.com/KB/10028},
urldate = {2016-11-02}
}
@misc{MoveItConcepts,
title = {{MoveIt Concepts - MoveIt Documentation}},
url = {http://moveit.ros.org/documentation/concepts/},
urldate = {2016-10-30}
}
@inproceedings{Tomasi1994,
abstract = {No feature-based vision system can work unless good features can be identified and tracked from frame to frame. Although tracking itself is by and large a solved problem, selecting features that can be tracked well and correspond to physical points in the world is still hard. We propose a feature selection criterion that is optimal by construction because it is based on how the tracker works, and a feature monitoring method that can detect occlusions, disocclusions, and features that do not correspond to points in the world. These methods are based on a new tracking algorithm that extends previous Newton-Raphson style search methods to work under affine image transformations. We test performance with several simulations and experiments},
author = {Shi, Jianbo and Tomasi, Carlo},
booktitle = {Computer Vision and Pattern Recognition, 1994. Proceedings CVPR '94., 1994 IEEE Computer Society Conference},
doi = {10.1109/CVPR.1994.323794},
file = {:C$\backslash$:/Users/CMobley7/Downloads/00323794.pdf:pdf},
isbn = {0-8186-5825-8},
issn = {1063-6919},
keywords = {Feature extraction,Machine vision,Newton-Raphson style search methods,Tracking,affine image transformations,computer vision,disocclusions,feature extraction,feature monitoring,feature selection,feature-based,occlusions,performance,tracker,tracking,vision system},
pages = {593--600},
pmid = {11968495},
title = {{Good Features To Track}},
year = {1994}
}
@misc{KDL,
title = {{Orocos KDL - ROS Wiki}},
url = {http://wiki.ros.org/orocos{\_}kdl},
urldate = {2016-10-31}
}
@misc{RGBColorSpace,
title = {{RGB Color Space - Wikipedia}},
url = {https://en.wikipedia.org/wiki/RGB{\_}color{\_}space},
urldate = {2016-10-30}
}
@article{Baker2004,
abstract = {Since the Lucas-Kanade algorithm was proposed in 1981 image alignment has become one of the most widely used techniques in computer vision. Applications range from optical flow and tracking to layered motion, mosaic construction, and face coding. Numerous algorithms have been proposed and a wide variety of extensions have been made to the original formulation. We present an overview of image alignment, describing most of the algorithms and their extensions in a consistent framework. We concentrate on the inverse compositional algorithm, an efficient algorithm that we recently proposed. We examine which of the extensions to Lucas-Kanade can be used with the inverse compositional algorithm without any significant loss of efficiency, and which cannot. In this paper, Part 1 in a series of papers, we cover the quantity approximated, the warp update rule, and the gradient descent approximation. In future papers, we will cover the choice of the error function, how to allow linear appearance variation, and how to impose priors on the parameters.},
author = {Baker, Simon and Matthews, Iain},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker, Matthews - 2004 - Lucas-Kanade 20 Years On A Unifying Framework.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {Gauss-Newton,Levenberg-Marquardt,Lucas-Kanade,Newton,a unifying framework,additive vs compositional algorithms,efficiency,for-wards vs inverse algorithms,image alignment,steepest descent,the inverse compositional algorithm},
number = {3},
pages = {221--255},
title = {{Lucas-Kanade 20 Years On: A Unifying Framework}},
volume = {56},
year = {2004}
}
@misc{TF2,
title = {{TF2 - ROS Wiki}},
url = {http://wiki.ros.org/tf2},
urldate = {2016-10-19}
}
@book{Szeliski2010,
abstract = {Humans perceive the three-dimensional structure of the world with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem and what is the current state of the art? Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging, and for fun, consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos. More than just a source of recipes, this exceptionally authoritative and comprehensive textbook/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting them to produce descriptions of a scene. These problems are also analyzed using statistical models and solved using rigorous engineering techniques Topics and features: structured to support active curricula and project-oriented courses, with tips in the Introduction for using the book in a variety of customized courses; presents exercises at the end of each chapter with a heavy emphasis on testing algorithms and containing numerous suggestions for small mid-term projects; provides additional material and more detailed mathematical topics in the Appendices, which cover linear algebra, numerical techniques, and Bayesian estimation theory; suggests additional reading at the end of each chapter, including the latest research in each sub-field, in addition to a full Bibliography at the end of the book; supplies supplementary course material for students at the associated website, http://szeliski.org/Book/. Suitable for an upper-level undergraduate or graduate-level course in computer science or engineering, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries. Its design and exposition also make it eminently suitable as a unique reference to the fundamental techniques and current research literature in computer vision.},
address = {New York, NY, USA},
author = {Szeliski, Richard},
edition = {1st},
isbn = {1848829345, 9781848829343},
publisher = {Springer-Verlag New York, Inc.},
title = {{Computer Vision: Algorithms and Applications}},
year = {2010}
}
@misc{MoveBase,
title = {{Move Base - ROS Wiki}},
url = {http://wiki.ros.org/move{\_}base},
urldate = {2016-11-04}
}
@misc{RobotLocalization,
title = {{Robot Localization - ROS Wiki}},
url = {http://wiki.ros.org/robot{\_}localization},
urldate = {2016-11-06}
}
@misc{Itseez2015,
author = {Itseez},
title = {{Open Source Computer Vision Library}},
url = {https://github.com/itseez/opencv},
year = {2015}
}
@article{Grisetti2007,
abstract = {Recently, Rao-Blackwellized particle filters (RBPF) have been introduced as an effective means to solve the simultaneous localization and mapping problem. This approach uses a particle filter in which each particle carries an individual map of the environment. Accordingly, a key question is how to reduce the number of particles. In this paper, we present adaptive techniques for reducing this number in a RBPF for learning grid maps. We propose an approach to compute an accurate proposal distribution, taking into account not only the movement of the robot, but also the most recent observation. This drastically decreases the uncertainty about the robot's pose in the prediction step of the filter. Furthermore, we present an approach to selectively carry out resampling operations, which seriously reduces the problem of particle depletion. Experimental results carried out with real mobile robots in large-scale indoor, as well as outdoor, environments illustrate the advantages of our methods over previous approaches},
author = {Grisetti, Giorgio and Stachniss, Cyrill and Burgard, Wolfram},
file = {:C$\backslash$:/Users/CMobley7/Downloads/grisetti06tro.pdf:pdf},
journal = {IEEE Transactions on Robotics},
keywords = {Adaptive resampling,Improved proposal,Motion model,Rao-Blackwellized particle filter (RBPF),Simultaneous localization and mapping (SLAM)},
number = {1},
pages = {34--46},
title = {{Improved techniques for grid mapping with Rao-Blackwellized particle filters}},
volume = {23},
year = {2007}
}
@misc{URDF,
title = {{URDF - ROS Wiki}},
url = {http://wiki.ros.org/urdf},
urldate = {2016-10-19}
}
@book{Wilson2000,
author = {Wilson, Joseph and Ritter, Gerhard},
edition = {Second},
isbn = {9781420042382},
publisher = {CRC Press},
title = {{Handbook of Computer Vision Algorithms in Image Algebra}},
year = {2000}
}
@inproceedings{Steux2010,
abstract = {This paper presents a Laser-SLAM algorithm which can be programmed in less than 200 lines C-language program. The first idea aimed to develop and implement a simple SLAM algorithm providing good performances without exceeding 200 lines in a C-language program. We use a robotic platform called MinesRover, a six wheels robot with several sensors. We based our work and calculations on a laser sensor and the odometry of the robot. The article presents the different capabilities of the platform and the way we use them in order to improve our programs. We also illustrates the difficulties encountered during the programming and testing of the algorithm. This work shows the possibility to perform complex tasks using simple and easily programmable algorithms.},
author = {Steux, Bruno and {El Hamzaoui}, Oussama},
booktitle = {11th International Conference on Control, Automation, Robotics and Vision, ICARCV 2010},
file = {:C$\backslash$:/Users/CMobley7/Downloads/05707402.pdf:pdf},
keywords = {Localization,Mapping,Particle filter,SLAM},
number = {December},
pages = {1975--1979},
title = {{tinySLAM: A SLAM algorithm in less than 200 lines C-language program}},
year = {2010}
}
@book{Millington2016,
author = {Millington, Ian and Funge, John},
isbn = {9781498785815},
publisher = {CRC Press},
title = {{Artificial Intelligence for Games}},
year = {2016}
}
@misc{GMapping,
title = {{GMapping - ROS Wiki}},
url = {http://wiki.ros.org/gmapping?distro=kinetic},
urldate = {2016-10-28}
}
@book{Thrun2005,
author = {Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter},
publisher = {The MIT Press},
title = {{Probabilistic Robotics (Intelligent Robotics and Autonomous Agents)}},
year = {2005}
}
@article{Smith1978,
abstract = {Digital control of color television monitors—in particular, via frame buffers—has added precise control of a large subset of human colorspace to the capabilities of computer graphics. This subset is the gamut of colors spanned by the red, green, and blue (RGB) electron guns exciting their respective phosphors. It is called the RGB monitor gamut. Full-blown color theory is a quite complex subject involving physics, psychology, and physiology, but restriction to the RGB monitor gamut simplifies matters substantially. It is linear, for example, and admits to familiar spatial representations. This paper presents a set of alternative models of the RGB monitor gamut based on the perceptual variables hue (H), saturation (S), and value (V) or brightness (L). Algorithms for transforming between these models are derived. Particular emphasis is placed on an RGB to HSV non-trigonometric pair of transforms which have been used successfully for about four years in frame buffer painting programs. These are fast, accurate, and adequate in many applications. Computationally more difficult transform pairs are sometimes necessary, however. Guidelines for choosing among the models are provided. Psychophysical corrections are described within the context of the definitions established by the NTSC (National Television Standards Committee).},
author = {Smith, Alvy Ray},
doi = {10.1145/965139.807361},
file = {:C$\backslash$:/Users/CMobley7/Downloads/p12-smith.pdf:pdf},
isbn = {0097-8930},
issn = {00978930},
journal = {ACM SIGGRAPH Computer Graphics},
keywords = {brightness,color,color transform,gamut,hue,luminance,ntsc,saturation,value},
number = {3},
pages = {12--19},
title = {{Color gamut transform pairs}},
volume = {12},
year = {1978}
}
@misc{KartoSLAM,
title = {{KartoSLAM - ROS Wiki}},
url = {http://wiki.ros.org/slam{\_}karto?distro=groovy},
urldate = {2016-10-28}
}
@misc{HectorSLAM,
title = {{HectorSLAM - ROS Wiki}},
url = {http://wiki.ros.org/hector{\_}slam},
urldate = {2016-10-28}
}
@book{Goebel2015,
author = {Goebel, Patrick},
publisher = {Lulu Enterprises, Inc.},
title = {{ROS By Example Volume 2: Packages and Programs for Advanced Robot Behaviors}},
year = {2015}
}
@book{Solomon2011,
author = {Solomon, Chris and Breckon, Toby},
isbn = {9781119957003},
publisher = {John Wiley {\&} Sons},
title = {{Fundamentals of Digital Image Processing: A Practical Approach with Examples in Matlab}},
year = {2011}
}
@inproceedings{Zhang1999,
abstract = {Proposes a flexible new technique to easily calibrate a camera. It$\backslash$nonly requires the camera to observe a planar pattern shown at a few (at$\backslash$nleast two) different orientations. Either the camera or the planar$\backslash$npattern can be freely moved. The motion need not be known. Radial lens$\backslash$ndistortion is modeled. The proposed procedure consists of a closed-form$\backslash$nsolution followed by a nonlinear refinement based on the maximum$\backslash$nlikelihood criterion. Both computer simulation and real data have been$\backslash$nused to test the proposed technique, and very good results have been$\backslash$nobtained. Compared with classical techniques which use expensive$\backslash$nequipment, such as two or three orthogonal planes, the proposed$\backslash$ntechnique is easy to use and flexible. It advances 3D computer vision$\backslash$none step from laboratory environments to real-world use. The$\backslash$ncorresponding software is available from the author's Web page$\backslash$n({\&}lt;http://research.microsoft.com/{\~{}}zhang{\&}gt;)},
author = {Zhang, Zhengyou Zhang Zhengyou},
booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.791289},
file = {:C$\backslash$:/Users/CMobley7/Downloads/zhan99.pdf:pdf},
isbn = {0-7695-0164-8},
issn = {01628828},
keywords = {camera calibration,flexible plane-based calibration,intrinsic parameters,lens distortion,model acquisition,motion analysis},
number = {c},
pages = {0--7},
title = {{Flexible camera calibration by viewing a plane from unknown orientations}},
volume = {1},
year = {1999}
}
@phdthesis{Smith2016,
author = {Smith, Evan Mclean},
file = {:C$\backslash$:/Users/CMobley7/Downloads/Smith{\_}EM{\_}T{\_}2016.pdf:pdf},
keywords = {autonomous navigation,computer vision,learning,linear infrastructure,machine,uav,unmanned aerial vehicle},
title = {{A Collection of Computer Vision Algorithms Capable of Detecting Linear Infrastructure for the Purpose of UAV Control A Collection of Computer Vision Algorithms Capable of Detecting Linear Infrastructure for the Purpose of UAV Control}},
year = {2016}
}
@misc{TracIK,
title = {{Trac IK - ROS Wiki}},
url = {http://wiki.ros.org/trac{\_}ik},
urldate = {2016-10-31}
}
@article{Canny1986,
abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
author = {Canny, John},
file = {:C$\backslash$:/Users/CMobley7/Downloads/6333402df1a75664260501522800cf3d26b9.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Edge detection,feature extraction,image processing,machine vision,multiscale image analysis},
number = {6},
pages = {679--698},
title = {{A Computational Approach to Edge Detection}},
volume = {PAMI-8},
year = {1986}
}
@article{Smith1986,
abstract = {This paper describes a general method for estimating the nominal relationship and expected error (covariance) between coordinate frames representing the relative locations of ob jects. The frames may be known only indirectly through a series of spatial relationships, each with its associated error, arising from diverse causes, including positioning errors, measurement errors, or tolerances in part dimensions. This estimation method can be used to answer such questions as whether a camera attached to a robot is likely to have a particular reference object in its field of view. The calculated estimates agree well with those from an independent Monte Carlo simulation. The method makes it possible to decide in advance whether an uncertain relationship is known accu rately enough for some task and, if not, how much of an improvement in locational knowledge a proposed sensor will provide. The method presented can be generalized to six degrees offreedom and provides a practical means of esti mating the relationships ( position and orientation) among objects, as well as estimating the uncertainty associated with the relationships.},
author = {Smith, Randall C and Cheeseman, Peter},
file = {:C$\backslash$:/Users/CMobley7/Downloads/Smith{\&}Cheeseman.pdf:pdf},
journal = {The International Journal of Robotics Research},
number = {4},
pages = {56--68},
title = {{On the Representation and Estimation of Spatial Uncertainty}},
volume = {5},
year = {1986}
}
@misc{AMCL,
title = {{AMCL - ROS Wiki}},
url = {http://wiki.ros.org/amcl},
urldate = {2016-11-04}
}
@inproceedings{Konolige2010,
abstract = {Pose graphs have become a popular representation for solving the simultaneous localization and mapping (SLAM) problem. A pose graph is a set of robot poses connected by nonlinear constraints obtained from observations of features common to nearby poses. Optimizing large pose graphs has been a bottleneck for mobile robots, since the computation time of direct nonlinear optimization can grow cubically with the size of the graph. In this paper, we propose an efficient method for constructing and solving the linear subproblem, which is the bottleneck of these direct methods. We compare our method, called Sparse Pose Adjustment (SPA), with competing indirect methods, and show that it outperforms them in terms of convergence speed and accuracy. We demonstrate its effectiveness on a large set of indoor real-world maps, and a very large simulated dataset. Open-source implementations in C++, and the datasets, are publicly available.},
author = {Konolige, Kurt and Grisetti, Giorgio and K??mmerle, Rainer and Burgard, Wolfram and Limketkai, Benson and Vincent, Regis},
booktitle = {IEEE/RSJ 2010 International Conference on Intelligent Robots and Systems, IROS 2010 - Conference Proceedings},
file = {:C$\backslash$:/Users/CMobley7/Downloads/spa2d.pdf:pdf},
pages = {22--29},
title = {{Efficient sparse pose adjustment for 2D mapping}},
year = {2010}
}
@misc{iai_kinect2,
address = {University Bremen},
annote = {Accessed June 12, 2015},
author = {Wiedemeyer, Thiemo},
howpublished = {$\backslash$url{\{}https://github.com/code-iai/iai$\backslash${\_}kinect2{\}}},
institution = {Institute for Artificial Intelligence},
title = {{IAI Kinect2}}
}
@inproceedings{Leonard1991,
abstract = {Discusses a significant open problem in mobile robotics: simultaneous map building and localization, which the authors define as long-term globally referenced position estimation without a priori information. This problem is difficult because of the following paradox: to move precisely, a mobile robot must have an accurate environment map; however, to build an accurate map, the mobile robot's sensing locations must be known precisely. In this way, simultaneous map building and localization can be seen to present a question of `which came first, the chicken or the egg?' (The map or the motion?) When using ultrasonic sensing, to overcome this issue the authors equip the vehicle with multiple servo-mounted sonar sensors, to provide a means in which a subset of environment features can be precisely learned from the robot's initial location and subsequently tracked to provide precise positioning},
author = {Leonard, J J and Durrant-Whyte, H F},
booktitle = {Intelligent Robots and Systems '91. 'Intelligence for Mechanical Systems, Proceedings IROS '91. IEEE/RSJ International Workshop on},
file = {:C$\backslash$:/Users/CMobley7/Downloads/00174711.pdf:pdf},
keywords = {autonomous mobile robot,computerised navigation,localization,long-term globally referenced position estimation,map building,mobile robots,multiple servo-mounted sonar sensors,path planning,planning (artificial intelligence),precise positioning,ultrasonic sensing},
number = {91},
pages = {1442--1447 vol.3},
title = {{Simultaneous map building and localization for an autonomous mobile robot}},
year = {1991}
}
@inproceedings{Santos2013,
abstract = {— In this work, a study of several laser-based 2D Simultaneous Localization and Mapping (SLAM) techniques available in Robot Operating System (ROS) is conducted. All the approaches have been evaluated and compared in 2D simulations and real world experiments. In order to draw conclusions on the performance of the tested techniques, the experimental results were collected under the same conditions and a generalized performance metric based on the k-nearest neighbors concept was applied. Moreover, the CPU load of each technique is examined. This work provides insight on the weaknesses and strengths of each solution. Such analysis is fundamental to decide which solution to adopt according to the properties of the intended final application.},
author = {Santos, Jo{\~{a}}o Machado and Portugal, David and Rocha, Rui P},
booktitle = {2013 IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR)},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Santos, Portugal, Rocha - Unknown - An Evaluation of 2D SLAM Techniques Available in Robot Operating System.pdf:pdf},
title = {{An Evaluation of 2D SLAM Techniques Available in Robot Operating System}},
year = {2013}
}
@misc{HowDigitalCamerasWork,
author = {Nice, Karim and Wilson, Tracy and Gurevich, Gerald},
title = {{How Digital Cameras Work}},
url = {http://electronics.howstuffworks.com/cameras-photography/digital/digital-camera.htm},
urldate = {2016-11-03}
}
@misc{RobotCalibration,
title = {{Robot Calibration - ROS Wiki}},
url = {http://wiki.ros.org/robot{\_}calibration},
urldate = {2016-11-07}
}
@misc{IKFast,
title = {{IKFast Module - OpenRAVE Documentation}},
url = {http://openrave.org/docs/latest{\_}stable/openravepy/ikfast/{\#}ikfast-the-robot-kinematics-compiler,},
urldate = {2016-10-31}
}
@misc{MapServer,
title = {{Map Server - ROS Wiki}},
url = {http://wiki.ros.org/map{\_}server},
urldate = {2016-11-04}
}
@inproceedings{Olson2011,
abstract = {— While the use of naturally-occurring features is a central focus of machine perception, artificial features (fiducials) play an important role in creating controllable experiments, ground truthing, and in simplifying the development of systems where perception is not the central objective. We describe a new visual fiducial system that uses a 2D bar code style " tag " , allowing full 6 DOF localization of features from a single image. Our system improves upon previous systems, incorporating a fast and robust line detection system, a stronger digital coding system, and greater robustness to occlusion, warping, and lens distortion. While similar in concept to the ARTag system, our method is fully open and the algorithms are documented in detail.},
author = {Olson, Edwin},
booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Olson - Unknown - AprilTag A robust and flexible visual fiducial system.pdf:pdf},
pages = {3400--3407},
title = {{AprilTag: A robust and flexible visual fiducial system}},
url = {http://april.eecs.umich.edu},
year = {2011}
}
@misc{ARTrackALVAR,
title = {{AR Track ALVAR - ROS Wiki}},
url = {http://wiki.ros.org/ar{\_}track{\_}alvar},
urldate = {2016-11-06}
}
@inproceedings{Quigley2009,
abstract = {— This paper gives an overview of ROS, an open-source robot operating system. ROS is not an operating system in the traditional sense of process management and scheduling; rather, it provides a structured communications layer above the host operating systems of a heterogenous compute cluster. In this paper, we discuss how ROS relates to existing robot software frameworks, and briefly overview some of the available application software which uses ROS.},
author = {Quigley, Morgan and Gerkey, Brian and Conley, Ken and Faust, Josh and Foote, Tully and Leibs, Jeremy and Berger, Eric and Wheeler, Rob and Ng, Andrew},
booktitle = {ICRA Workshop on Open Source Software},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Quigley et al. - Unknown - ROS an open-source Robot Operating System.pdf:pdf},
title = {{ROS: an open-source Robot Operating System}},
year = {2009}
}
@misc{IK,
title = {{Inverse Kinematics - Wikipedia}},
url = {https://en.wikipedia.org/wiki/Inverse{\_}kinematics},
urldate = {2016-10-31}
}
@article{Grisetti2010a,
author = {Grisetti, Giorgio and Kummerle, Rainer and Stachniss, Cyrill and Burgard, Wolfram},
file = {:C$\backslash$:/Users/CMobley7/Downloads/slamtutorial.pdf:pdf},
journal = {IEEE Intelligent Transportation Systems Magazine},
number = {4},
pages = {31--43},
title = {{A tutorial on graph-based SLAM}},
volume = {2},
year = {2010}
}
@misc{TF,
title = {{TF - ROS Wiki}},
url = {http://wiki.ros.org/tf},
urldate = {2016-10-19}
}
@misc{OpenSLAM,
title = {{OpenSLAM - What is SLAM?}},
url = {http://openslam.org/},
urldate = {2016-10-28}
}
@misc{ParamServer,
title = {{Parameter Server - ROS Wiki}},
url = {http://wiki.ros.org/Parameter Server},
urldate = {2016-10-30}
}
@misc{ALVAR,
title = {{ALVAR Toolkit Website}},
url = {http://virtual.vtt.fi/virtual/proj2/multimedia/alvar/index.html},
urldate = {2016-10-29}
}
@misc{Quadri,
author = {Quadri, S.A.},
title = {{What is Spatial Resolution?}},
url = {http://www.slideshare.net/reachquadri/what-is-spatial-resolution},
urldate = {2016-11-02}
}
@misc{BinaryImage,
title = {{Binary Image - Wikipedia}},
url = {https://en.wikipedia.org/wiki/Binary{\_}image},
urldate = {2016-11-03}
}
@article{Illingworth1987,
abstract = {We introduce the Adaptive Hough Transform, AHT, as an efficient way of implementing the Hough Transform, HT, method for the detection of 2-D shapes. The AHT uses a small accumulator array and the idea of a flexible iterative "coarse to fine" accumulation and search strategy to identify significant peaks in the Hough parameter spaces. The method is substantially superior to the standard HT implementation in both storage and computational requirements. In this correspondence we illustrate the ideas of the AHT by tackling the problem of identifying linear and circular segments in images by searching for clusters of evidence in 2-D parameter spaces. We show that the method is robust to the addition of extraneous noise and can be used to analyze complex images containing more than one shape.},
author = {Illingworth, J. and Kittler, J.},
file = {:C$\backslash$:/Users/CMobley7/Downloads/04767964.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {5},
pages = {690--698},
title = {{The Adaptive Hough Transform}},
volume = {PAMI-9},
year = {1987}
}
@misc{Bouguet2015,
author = {Bouguet, Jean-Yves},
title = {{Camera Calibration Toolbox For Matlab}},
url = {https://www.vision.caltech.edu/bouguetj/calib{\_}doc/index.html},
urldate = {2016-11-06},
year = {2015}
}
@techreport{Diankov2008,
abstract = {One of the challenges in developing real-world autonomous robots is the need for integrating and rigorously test- ing high-level scripting, motion planning, perception, and control algorithms. For this purpose, we introduce an open-source cross-platform software architecture called OpenRAVE, the Open Robotics and Animation Virtual Envi- ronment. OpenRAVE is targeted for real-world autonomous robot applications, and includes a seamless integration of 3-D simulation, visualization, planning, scripting and control. A plugin architecture allows users to easily write cus- tom controllers or extend functionality. With OpenRAVE plugins, any planning algorithm, robot controller, or sensing subsystem can be distributed and dynamically loaded at run-time, which frees developers from struggling with mono- lithic code-bases. Users of OpenRAVE can concentrate on the development of planning and scripting aspects of a problem without having to explicitly manage the details of robot kinematics and dynamics, collision detection, world updates, and robot control. The OpenRAVE architecture provides a flexible interface that can be used in conjunction with other popular robotics packages such as Player and ROS because it is focused on autonomous motion planning and high-level scripting rather than low-level control and message protocols. OpenRAVE also supports a powerful network scripting environment which makes it simple to control and monitor robots and change execution flow dur- ing run-time. One of the key advantages of open component architectures is that they enable the robotics research community to easily share and compare algorithms.},
address = {Pittsburgh, PA},
author = {Diankov, Rosen and Kuffner, James},
booktitle = {Robotics},
doi = {CMU-RI-TR-08-34},
file = {:C$\backslash$:/Users/CMobley7/Downloads/3dc33b629916a306cc58cbff05dcd632d42d.pdf:pdf},
institution = {Robotics Institute, Carnegie Mellon University},
number = {July},
title = {{OpenRAVE : A Planning Architecture for Autonomous Robotics}},
year = {2008}
}
@misc{FK,
title = {{Forward Kinematics - Wikipedia}},
url = {https://en.wikipedia.org/wiki/Forward{\_}kinematics},
urldate = {2016-10-31}
}
@misc{RGBColorModel,
title = {{RGB Color Model - Wikipedia}},
url = {https://en.wikipedia.org/wiki/RGB{\_}color{\_}model},
urldate = {2016-10-30}
}
@inproceedings{Kohlbrecher2011,
abstract = {For many applications in Urban Search and Rescue (USAR) scenarios robots need to learn a map of unknown environments. We present a system for fast online learning of occupancy grid maps requiring low computational resources. It combines a robust scan matching approach using a LIDAR system with a 3D attitude estimation system based on inertial sensing. By using a fast approximation of map gradients and a multi-resolution grid, reliable localization and mapping capabilities in a variety of challenging environments are realized. Multiple datasets showing the applicability in an embedded hand-held mapping system are provided. We show that the system is sufficiently accurate as to not require explicit loop closing techniques in the considered scenarios. The software is available as an open source package for ROS.},
author = {Kohlbrecher, Stefan and {Von Stryk}, Oskar and Meyer, Johannes and Klingauf, Uwe},
booktitle = {9th IEEE International Symposium on Safety, Security, and Rescue Robotics, SSRR 2011},
file = {:C$\backslash$:/Users/CMobley7/Downloads/10.1.1.302.2579.pdf:pdf},
keywords = {Inertial Navigation,Robust and Fast Localization,Simultaneous Localization and Mapping},
pages = {155--160},
title = {{A flexible and scalable SLAM system with full 3D motion estimation}},
year = {2011}
}
@phdthesis{Burton2015,
abstract = {(ABSTRACT) As robotic systems grow in complexity, they inevitably undergo a process of specialization whereby they separate into an array of interconnected subsystems and individual processes. In order to function as a unified system, these processes rely heavily on interprocess com-munications (IPC) to transfer information between subsystems and various execution loops. This thesis presents the design, implementation, and validation of the Valor ROS Controller, a hybrid IPC interface layer and robot controller. The Valor ROS Controller connects the motion control system, implemented with the internally created Bifrost IPC, developed by Team VALOR for the DARPA Robotics Challenge (DRC) with the high level software de-veloped by Team ViGIR that uses the Robot Operating System (ROS) IPC framework. The Valor ROS Controller also acts as a robot controller designed to run on THOR and ES-CHER, and is configurable to use different control modes and controller implementations. By combining an IPC interface layer with controllers, the Valor ROS Controller enabled Team VALOR to use Team ViGIR's software capabilities at the DRC Finals. In addition to the qualitative validation of Team VALOR competing at the DRC Finals, this thesis studies the efficiency of the Valor ROS Controller by quantifying its computational resourceful utilization, message pathway latency, and joint controller tracking. Another con-tribution of this thesis is the quantification of end-effector pose error incurred by whole-body motions. This phenomenon has been observed on both THOR and ESCHER as one of their arms moves through a trajectory, however, it has never been studied in depth on either robot. The results demonstrate that the Valor ROS Controller adequately uses computational re-sources and has message latencies in the order of 50 ms. The results also indicate several avenues to improve arm tracking in Team VALOR's system. Whole-body motions account for approximately 5 cm of the end-effector pose error observed on hardware when an arm is at near full extension.},
author = {Burton, James David},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Burton et al. - 2015 - Development and Characterization of an Interprocess Communications Interface and Controller for Bipedal Robots.pdf:pdf},
keywords = {Bifrost,Humanoid Robot,Interprocess Communications,ROS,Robot Controller},
title = {{Development and Characterization of an Interprocess Communications Interface and Controller for Bipedal Robots}},
year = {2015}
}
@book{Schowengerdt2012,
author = {Schowengerdt, Robert},
isbn = {9780080516103},
publisher = {Elsevier Science},
title = {{Remote Sensing: Models and Methods for Image Processing}},
year = {2012}
}
@inproceedings{Beeson2015,
abstract = {The Inverse Kinematics (IK) algorithms implemented in the open-source Orocos Kinematics and Dynamics Library (KDL) are arguably the most widely-used generic IK solvers worldwide. However, KDL's only joint-limit-constrained IK implementation, a pseudoinverse Jacobian IK solver, repeatedly exhibits false-negative failures on various humanoid platforms. In order to find a better IK solver for generic manipulator chains, a variety of open-source, drop-in alternatives have been implemented and evaluated for this paper. This article provides quantitative comparisons, using multiple humanoid platforms, between an improved implementation of the KDL inverse Jacobian algorithm, a set of sequential quadratic programming (SQP) IK algorithms that use a variety of quadratic error metrics, and a combined algorithm that concurrently runs the best performing SQP algorithm and the improved inverse Jacobian implementation. The best alternative IK implementation finds solutions much more often than KDL, is faster on average than KDL for typical manipulation chains, and (when desired) allows tolerances on each Cartesian dimension, further improving speed and convergence when an exact Cartesian pose is not possible and/or necessary.},
author = {Beeson, Patrick and Ames, Barrett},
booktitle = {IEEE-RAS International Conference on Humanoid Robots},
doi = {10.1109/HUMANOIDS.2015.7363472},
file = {:C$\backslash$:/Users/CMobley7/Downloads/Beeson-humanoids-15.pdf:pdf},
isbn = {9781479968855},
issn = {21640580},
keywords = {Heuristic algorithms,Jacobian matrices,Kinematics,Measurement,Optimization,Quaternions,Robots},
pages = {928--935},
title = {{TRAC-IK: An open-source library for improved solving of generic inverse kinematics}},
volume = {2015-Decem},
year = {2015}
}
@misc{DigitalCamera,
title = {{How Does a Digital Camera Work?}},
url = {https://www.google.com/url?sa=i{\&}rct=j{\&}q={\&}esrc=s{\&}source=images{\&}cd={\&}ved=0ahUKEwjy3uuhwovQAhUE24MKHe6DCMIQjxwIAw{\&}url=http{\%}3A{\%}2F{\%}2Fwww.notey.com{\%}2Fblogs{\%}2Fadc-travels{\%}3Fpage{\%}3D2{\&}psig=AFQjCNFBhPHyArfz8DKZ4GolmgBgRXlyTQ{\&}ust=1478225767235938},
urldate = {2016-11-02}
}
@inproceedings{Latif2013,
author = {Latif, Doaa M. a and {Megeed Salem}, Mohammed a. and Ramadan, H. and Roushdy, Mohamed I.},
booktitle = {Proceedings of the 4th European Conference of Computer Science (ECCS '13) Recent Advances in Information Science},
file = {:C$\backslash$:/Users/CMobley7/Downloads/ECCS-31.pdf:pdf},
number = {October},
pages = {288},
title = {{Comparison of Optimization Techniques for 3D Graph-based}},
year = {2013}
}
@inproceedings{Vincent2010,
author = {Vincent, Regis and Limketkai, Benson and Eriksen, Michael},
booktitle = {SPIE 7664, Detection and Sensing of Mines, Explosive Objects, and Obscured Targets XV},
editor = {Harmon, Russell S. and {Holloway, Jr.}, John H. and Broach, J. Thomas},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Vincent, Limketkai, Eriksen - 2010 - Comparison of indoor robot localization techniques in the absence of GPS.pdf:pdf},
keywords = {Algorithms,Cameras,Laser range finders,Lasers},
month = {apr},
pages = {76641Z},
publisher = {International Society for Optics and Photonics},
title = {{Comparison of indoor robot localization techniques in the absence of GPS}},
year = {2010}
}
@book{Pitas2000,
author = {Pitas, Ioannis},
isbn = {9780471377399},
publisher = {John Wiley {\&} Sons},
title = {{Digital Image Processing Algorithms and Applications}},
year = {2000}
}
@book{Fleet2014,
author = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
isbn = {9783319105840},
publisher = {Springer International Publishing},
title = {{Computer Vision -- ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part 7}},
year = {2014}
}
@book{Jain1995,
author = {Jain, Ramesh and Kasturi, Rangachar and Schunck, Brian},
isbn = {9780070320185},
publisher = {McGraw-Hill},
title = {{Machine Vision}},
year = {1995}
}
@misc{ARTrackAlvar,
title = {{AR Track Alvar - ROS Wiki}},
url = {http://wiki.ros.org/ar{\_}track{\_}alvar},
urldate = {2016-10-29}
}
@article{Smith1990,
abstract = {In this paper, we describe a representation for spatial information, called the stochastic map, and associated procedures for building it, reading information from it, and revising it incrementally as new information is obtained. The map contains the estimates of relationships among objects in the map, and their un- certainties, given all the available information. The procedures provide a general solution to the problem of estimating uncertain relative spatial relationships. The estimates are probabilistic in nature, an advance over the previous, very conservative, worst-case approaches to the problem. Finally, the procedures are developed in the context of state-estimation and filtering theory, which provides a solid basis for numerous extensions.},
author = {Smith, R. and Self, M. and Cheeseman, P.},
file = {:C$\backslash$:/Users/CMobley7/Downloads/chp{\%}3A10.1007{\%}2F978-1-4613-8997-2{\_}14.pdf:pdf},
journal = {Autonomous Robot Vehicles},
number = {April},
pages = {167--193},
title = {{Estimating Uncertain Spatial Relationships in Robotics}},
volume = {4},
year = {1990}
}
@misc{ROSWebsite,
title = {{ROS.org - Powering the world's robots}},
url = {http://www.ros.org/},
urldate = {2016-10-18}
}
@misc{Parikh2015,
author = {Parikh, Devi},
title = {{Linear Filters [PowerPoint Presentation] - ECE 5554: Computer Vision}},
url = {https://filebox.ece.vt.edu/{~}F15ECE5554ECE4984/lectures/parikh{\_}lecture2{\_}filters.pptx},
urldate = {2015-08-27},
year = {2015}
}
@misc{BaseLocalPlanner,
title = {{Base Local Planner - ROS Wiki}},
url = {http://wiki.ros.org/base{\_}local{\_}planner},
urldate = {2016-10-17}
}
@misc{LagoSLAM,
title = {{LagoSLAM - ROS Wiki}},
url = {https://github.com/rrg-polito/rrg-polito-ros-pkg},
urldate = {2016-10-28}
}
@misc{RVIZ,
title = {{RVIZ - ROS Wiki}},
url = {http://wiki.ros.org/rviz},
urldate = {2016-10-30}
}
@misc{SRDF,
title = {{SRDF - ROS Wiki}},
url = {http://wiki.ros.org/srdf},
urldate = {2016-10-30}
}
@misc{ARToolKit,
title = {{ARToolKit Website}},
url = {http://www.hitl.washington.edu/artoolkit/},
urldate = {2016-10-29}
}
@phdthesis{Sanni2012,
author = {Siltanen, Sanni},
file = {:C$\backslash$:/Users/CMobley7/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Siltanen - Unknown - Theory and applications of marker-based augmented reality(2).pdf:pdf},
keywords = {AR,Augmented reality,diminished reality,marker-based tracking,markers,mixed reality,tracking,visualization},
publisher = {VTT science},
title = {{Theory and applications of marker-based augmented reality}},
year = {2012}
}
@misc{TRACLab,
title = {{TRACLab - An Exploratory Research Lab Driven by a Curious, Pioneering Spirit.}},
url = {https://traclabs.com/},
urldate = {2016-10-31}
}
@inproceedings{Asadi2015,
abstract = {In this work a library for solving manipulator motion planning problems has been developed and an algorithm for imposing Cartesian constraint in single arm and dual arm operation has been proposed. The main algorithm is based on RRT [1]. The code has been tested with several single arm and dual arm robots. We have achieved to find collision free paths in environments occupied with obstacles. Example of such environments is the shelf from Amazon picking challenge. The implemented code also enabled us to perform complicated dual arm operations such as opening a hand wheel or opening a drawer.},
author = {Asadi, Behnam},
booktitle = {Workshop on Task Planning for Intelligent Robots in Service and Manufacturing. IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Workshop on Task Planning for Intelligent Robots in Service and Manufacturing, located at IROS 2015},
file = {:C$\backslash$:/Users/CMobley7/Downloads/taskplan2015iros{\_}paper{\_}7.pdf:pdf},
keywords = {Manipulator motion planning,dual arm operation,planning under Cartesian constraint,robotics.},
title = {{Single and Dual Arm Manipulator Motion Planning Library}},
year = {2015}
}
@misc{SMACH,
title = {{SMACH - ROS Wiki}},
url = {http://wiki.ros.org/smach},
urldate = {2016-10-31}
}
